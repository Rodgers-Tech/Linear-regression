{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of linear-regression-demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rodgers-Tech/Linear-regression/blob/master/Copy_of_linear_regression_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM1tzPvICydP"
      },
      "source": [
        "**Press shift+enter to execute a cell**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtGzW6k4-epp"
      },
      "source": [
        "# Simple Linear Regression\n",
        "\n",
        "The goal of this notebook is to demonstrate a linear regression model from the ground up using numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k77xaJfA-epq"
      },
      "source": [
        "%matplotlib inline\n",
        "from IPython.display import HTML\n",
        "from numpy import *\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8NSLCXfIE13"
      },
      "source": [
        "#### Download dataset to colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wPsqGPFIUn4"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIdjicszDkAf"
      },
      "source": [
        "import urllib\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/CC-MNNIT/2018-19-Classes/master/MachineLearning/2018_08_22_Logical-Rhythm-2/data.csv\", \"data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcjydmnBEn2O"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU4LfMDe-ept"
      },
      "source": [
        "#### Import the data\n",
        "Here, we're using a dataset with two columns containing the amount of hours studied and the test scores students achieved, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9HoBdK3-epu"
      },
      "source": [
        "data = genfromtxt('data.csv', delimiter=',')\n",
        "\n",
        "#Extract columns\n",
        "x = array(data[:,0])\n",
        "y = array(data[:,1])\n",
        "\n",
        "#Plot the dataset\n",
        "plt.scatter(x,y)\n",
        "plt.xlabel('Hours of study')\n",
        "plt.ylabel('Test scores')\n",
        "plt.title('Dataset')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9jBqpSy-epx"
      },
      "source": [
        "#### Defining the hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgOidX2L-epy"
      },
      "source": [
        "#hyperparamters\n",
        "learning_rate = 0.0001\n",
        "initial_b = 0\n",
        "initial_m = 0\n",
        "num_iterations = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2FOk0Nc-ep1"
      },
      "source": [
        "#### Define cost function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiXWph9g-ep1"
      },
      "source": [
        "def compute_cost(b, m, data):\n",
        "    total_cost = 0\n",
        "    \n",
        "    # number of datapoints in training data\n",
        "    N = float(len(data))\n",
        "    \n",
        "    # Compute sum of squared errors\n",
        "    for i in range(0, len(data)):\n",
        "        x = data[i, 0]\n",
        "        y = data[i, 1]\n",
        "        total_cost += (y - (m * x + b)) ** 2\n",
        "        \n",
        "    # Return average of squared error\n",
        "    return total_cost/(2*N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSObpG-b-ep4"
      },
      "source": [
        "#### Define Gradient Descent functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7dQ8n5m-ep5"
      },
      "source": [
        "def step_gradient(b_current, m_current, data, alpha):\n",
        "    \"\"\"takes one step down towards the minima\n",
        "    \n",
        "    Args:\n",
        "        b_current (float): current value of b\n",
        "        m_current (float): current value of m\n",
        "        data (np.array): array containing the training data (x,y)\n",
        "        alpha (float): learning rate / step size\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (b,m) new values of b,m\n",
        "    \"\"\"\n",
        "    \n",
        "    m_gradient = 0\n",
        "    b_gradient = 0\n",
        "    N = float(len(data))\n",
        "\n",
        "    # Calculate Gradient\n",
        "    for i in range(0, len(data)):\n",
        "        x = data[i, 0]\n",
        "        y = data[i, 1]\n",
        "        m_gradient += - (2/N) * x * (y - (m_current * x + b_current))\n",
        "        b_gradient += - (2/N) * (y - (m_current * x + b_current))\n",
        "    \n",
        "    # Update current m and b\n",
        "    m_updated = m_current - alpha * m_gradient\n",
        "    b_updated = b_current - alpha * b_gradient\n",
        "\n",
        "    #Return updated parameters\n",
        "    return b_updated, m_updated\n",
        "\n",
        "def gradient_descent(data, starting_b, starting_m, learning_rate, num_iterations):\n",
        "    \"\"\"runs gradient descent\n",
        "    \n",
        "    Args:\n",
        "        data (np.array): training data, containing x,y\n",
        "        starting_b (float): initial value of b (random)\n",
        "        starting_m (float): initial value of m (random)\n",
        "        learning_rate (float): hyperparameter to adjust the step size during descent\n",
        "        num_iterations (int): hyperparameter, decides the number of iterations for which gradient descent would run\n",
        "    \n",
        "    Returns:\n",
        "        list : the first and second item are b, m respectively at which the best fit curve is obtained, the third and fourth items are two lists, which store the value of b,m as gradient descent proceeded.\n",
        "    \"\"\"\n",
        "\n",
        "    # initial values\n",
        "    b = starting_b\n",
        "    m = starting_m\n",
        "    \n",
        "    # to store the cost after each iteration\n",
        "    cost_graph = []\n",
        "    \n",
        "    # to store the value of b -> bias unit, m-> slope of line after each iteration (pred = m*x + b)\n",
        "    b_progress = []\n",
        "    m_progress = []\n",
        "    \n",
        "    # For every iteration, optimize b, m and compute its cost\n",
        "    for i in range(num_iterations):\n",
        "        cost_graph.append(compute_cost(b, m, data))\n",
        "        b, m = step_gradient(b, m, array(data), learning_rate)\n",
        "        b_progress.append(b)\n",
        "        m_progress.append(m)\n",
        "        \n",
        "    return [b, m, cost_graph,b_progress,m_progress]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v-y-qI3-ep7"
      },
      "source": [
        "#### Run gradient_descent() to get optimized parameters b and m"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV6KIdPq-ep7"
      },
      "source": [
        "b, m, cost_graph,b_progress,m_progress = gradient_descent(data, initial_b, initial_m, learning_rate, num_iterations)\n",
        "\n",
        "#Print optimized parameters\n",
        "print ('Optimized b:', b)\n",
        "print ('Optimized m:', m)\n",
        "\n",
        "#Print error with optimized parameters\n",
        "print ('Minimized cost:', compute_cost(b, m, data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnmqepye-ep_"
      },
      "source": [
        "#### Plotting the cost per iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1VREIE7-eqA"
      },
      "source": [
        "plt.plot(cost_graph)\n",
        "plt.xlabel('No. of iterations')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('Cost per iteration')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWQAkFE8-eqD"
      },
      "source": [
        "Gradient descent converges to local minimum after 5 iterations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT2wKbHu-eqE"
      },
      "source": [
        "#### Plot line of best fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD531y8K-eqF"
      },
      "source": [
        "#Plot dataset\n",
        "plt.scatter(x, y)\n",
        "#Predict y values\n",
        "pred = m * x + b\n",
        "#Plot predictions as line of best fit\n",
        "plt.plot(x, pred, c='r')\n",
        "plt.xlabel('Hours of study')\n",
        "plt.ylabel('Test scores')\n",
        "plt.title('Line of best fit')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeXdBWc-Cic-"
      },
      "source": [
        "### Gradient descent's progress with num of iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHGbi8nY-eqI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "b9cbfefd-9014-41ad-9999-d74dece5f9bd"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.animation as animation\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "b = b_progress[0]\n",
        "m = m_progress[0]\n",
        "pred = m*x + b\n",
        "\n",
        "line = ax.plot(x,pred, '-',c='r')[0]\n",
        "\n",
        "def animate(i,b_prog,m_prog):\n",
        "    pred = m_prog[i] * x + b_prog[i]\n",
        "    line.set_data(x,pred)\n",
        "    return line,\n",
        "\n",
        "ani = animation.FuncAnimation(fig, animate, frames=len(b_progress), fargs=(b_progress,m_progress,))\n",
        "ax.scatter(x,y)\n",
        "HTML(ani.to_jshtml())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6d54ce7d7812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_progress\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_progress\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'b_progress' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}